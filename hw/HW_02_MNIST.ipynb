{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5112f03",
   "metadata": {},
   "source": [
    "# Домашнее задание по теме \"Многослойная нейронная сеть\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434593b",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Постройте модель на основе полносвязных слоёв для классификации Fashion MNIST из библиотеки torchvision (datasets).\n",
    "Получите качество на тестовой выборке не ниже 88%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee1974",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a4ed3",
   "metadata": {},
   "source": [
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9e30450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision as tv\n",
    "from  torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c147249c",
   "metadata": {},
   "source": [
    "### Пременные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "manual_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345122c4",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "27f7d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3a695fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=transform, download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cfa36271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabf4a4f",
   "metadata": {},
   "source": [
    "### Разделение обучающего датасета на обучающую и валидационную выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6a117fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarin_size = 48000\n",
      "val_size = 12000\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "print(f\"tarin_size = {train_size}\")\n",
    "print(f\"val_size = {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "109cb15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(manual_seed)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0028b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a4ff002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "36fc783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19550028",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "496da504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0dbc1921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8ee03a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.005)\n",
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6a1ae2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop():\n",
    "    for epoch in range(num_epochs):\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "\n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "\n",
    "        val_iters, val_passed = 0, 0\n",
    "        val_loss, val_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in val:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            val_loss  += l.item()\n",
    "            val_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            val_iters += 1\n",
    "            val_passed += len(X)\n",
    "\n",
    "        print(\"epoch: {}, taked: {: .3f}, train_loss: {}, train_acc: {}, val_loss: {}, val_acc: {}\".format(\n",
    "            epoch, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            val_loss / val_iters, val_acc / val_passed\n",
    "        ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "57f2706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, taked:  14.622, train_loss: 0.4877846153809669, train_acc: 0.8214375, val_loss: 0.42984733239133305, val_acc: 0.84725\n",
      "epoch: 1, taked:  14.440, train_loss: 0.3797557198620857, train_acc: 0.8593333333333333, val_loss: 0.40489046941412254, val_acc: 0.8543333333333333\n",
      "epoch: 2, taked:  13.887, train_loss: 0.3410563824024606, train_acc: 0.8738125, val_loss: 0.4199260910774799, val_acc: 0.8553333333333333\n",
      "epoch: 3, taked:  13.889, train_loss: 0.32415946430348336, train_acc: 0.8789166666666667, val_loss: 0.4039122297408733, val_acc: 0.8629166666666667\n",
      "epoch: 4, taked:  14.413, train_loss: 0.3008923899144568, train_acc: 0.888, val_loss: 0.37447173291064323, val_acc: 0.8726666666666667\n",
      "epoch: 5, taked:  14.578, train_loss: 0.2873751166019034, train_acc: 0.8921875, val_loss: 0.38609771684129185, val_acc: 0.8726666666666667\n",
      "epoch: 6, taked:  14.585, train_loss: 0.26690304826231714, train_acc: 0.899, val_loss: 0.42983080415015523, val_acc: 0.8629166666666667\n",
      "epoch: 7, taked:  14.797, train_loss: 0.2570348673678459, train_acc: 0.9031458333333333, val_loss: 0.4386943334594686, val_acc: 0.8771666666666667\n",
      "epoch: 8, taked:  14.624, train_loss: 0.24819415720536353, train_acc: 0.9051458333333333, val_loss: 0.4284433969791899, val_acc: 0.8774166666666666\n",
      "epoch: 9, taked:  14.776, train_loss: 0.23560806435156376, train_acc: 0.9113541666666667, val_loss: 0.4604881570694294, val_acc: 0.8644166666666667\n",
      "epoch: 10, taked:  14.290, train_loss: 0.22587808063055606, train_acc: 0.9146875, val_loss: 0.37489003957586087, val_acc: 0.87675\n",
      "epoch: 11, taked:  14.536, train_loss: 0.22006136432607123, train_acc: 0.916875, val_loss: 0.4150026190154096, val_acc: 0.8775833333333334\n",
      "epoch: 12, taked:  14.463, train_loss: 0.20917859808244604, train_acc: 0.9208541666666666, val_loss: 0.4123800704453854, val_acc: 0.8799166666666667\n",
      "epoch: 13, taked:  14.578, train_loss: 0.2010423943717429, train_acc: 0.9234583333333334, val_loss: 0.4308140233476111, val_acc: 0.887\n",
      "epoch: 14, taked:  15.086, train_loss: 0.19420522011499455, train_acc: 0.927375, val_loss: 0.40021028005062265, val_acc: 0.8864166666666666\n"
     ]
    }
   ],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a8537c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели на тестовой выборке: 88.12%. Поставленная цель достигнута.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "if accuracy >= 88:\n",
    "    print(f\"Точность модели на тестовой выборке: {accuracy:.2f}%. Поставленная цель достигнута.\")\n",
    "else:\n",
    "    print(f\"Точность модели на тестовой выборке: {accuracy:.2f}%. Поставленная цель еще не достигнута. Удачи!\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netology_pytorch_project",
   "language": "python",
   "name": "netology_pytorch_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
